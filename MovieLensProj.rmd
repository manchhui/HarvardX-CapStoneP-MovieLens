---
title: 'Data Science: Capstone Project - Movie Lens Report'
author: "Man Chun Hui"
year: '2019'
output:
  pdf_document: 
    number_sections: true
abstract: "In this **project**, we created a movie recommendation system using a large subset of the MovieLens dataset. Exploration of the _edx_ dataset showed strong evidence of a genre effect and if used to augment the **_Regularized Movie + User Effect Model_**^[https://rafalab.github.io/dsbook/large-datasets.html#recommendation-systems] could yield improvements in the accuracy of the model. This hypothesis was validated when the final model, with the addition of an regularized predicted genre effect \"*bias*\" term, yielded a residual mean squared error (**RMSE**) of **0.8575** on the _validation_ dataset."
geometry: margin=0.7in
fontfamily: mathpazo
fontsize: 11pt
# spacing: double
endnote: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dslabs)
library(tidyverse)
library(caret)
library(knitr)
library(gridExtra)
load("rda/edxrows.rda")
load("rda/edxcols.rda")
load("rda/n_movies.rda")
load("rda/n_users.rda")
load("rda/edxtrows.rda")
load("rda/p1.rda")
load("rda/p2.rda")
load("rda/p3.rda")
load("rda/p4.rda")
load("rda/p5.rda")
load("rda/lambda.rda")
load("rda/lambdas.rda")
load("rda/rmses.rda")
load("rda/RMSE_Final.rda")
```

# Introduction
The goal of this project was to create a movie recommendation system using a subset of the MovieLens dataset generated by the the GroupLens research lab^[https://grouplens.org/]. It is worth noting that the version of the movielens dataset included in the dslabs package (which was used for some of the exercises in PH125.8x: Data Science: Machine Learning) is just a small subset of the much larger dataset which has millions of ratings, whereas in this project we be will using a larger proportion of the MovieLens dataset, that has 10M ratings, to help create our recommendation system.

The code provided in the project brief partitions the Movielens data into two seperate subsets one named **edx** and the other **validation**. The **edx** subset was used to train a machine learning algorithm and the **validation** subset was used to predict movie ratings and provide the final **RMSE** value. 

```{r edx dataset exploration part1, echo=FALSE, eval=TRUE}
df <- data.frame(edxtrows$userId, edxtrows$movieId, edxtrows$rating, edxtrows$timestamp, edxtrows$title, edxtrows$genres)
colnames(df) <- c('userId', 'movieId', 'rating', 'timestamp', 'title', 'genres') 
kable(df, caption = "EDX dataset exploration")
```

Exploration of the **edx** subset, in Table 1 above and Table 2 below, showed that the data is in tidy format with each row representing a rating given by one user to one movie and in total there are approximately 9M ratings from 69,878 unique users that provided ratings for 10,677 unique movies. 

```{r edx dataset exploration part2, echo=FALSE, eval=TRUE}
df <- data.frame(edxrows,edxcols,n_movies,n_users)
colnames(df) <- c('No. Of Rows', 'No. Of Columns', 'No. of Movies', 'No. Of Users') 
kable(df, caption = "EDX dataset exploration")
```

# Methods / Analysis
## Movielens edx data
Exploration of the edx data confirmed that the observations^[https://rafalab.github.io/dsbook/large-datasets.html#movielens-data, **Observation 1** - Not every user rated every movie, **Observation 2** - Some movies get rated more than others, **Observation 3** - Some users are more active than others at rating movies.] noted in **_Chapter 33.7.1 - Movielens data_** of the smaller movielens data set still holds true for the larger dataset,  this therefore confirms the continued usefulness that movie effects and users effects will have on predicting moving ratings.

```{r edx dataset exploration part3, echo=FALSE, fig.width=6, fig.height=2, fig.align='center'}
grid.arrange(p1,p2, ncol=2, nrow=1)
```

To improve accuracy of the ML algorithm / model it was necessary to explore if either of the remaining predictors, timestamp or genres, in the edx dataset could prove useful. It quickly became evident, from the two figures below, that there is a genre effect where certain genres are rated more than others while there is little evidence of a useful time effect as the average rating is fairly consistant overtime.

```{r edx dataset exploration part4, echo=FALSE, fig.width=6, fig.height=2, fig.align='center'}
grid.arrange(p3,p4, ncol=2, nrow=1)
```

## Modelling genre effects
Adapting the model detailed in **_Chapter 33.7.6 - User Effects_**^[https://rafalab.github.io/dsbook/large-datasets.html#user-effects] to add the genre effects term to predict the rating of a movie **_i_** by user **_u_** with different biases for different genre's **_g_**: 

$$Y_{g,u,i} = \mu + b_{i} + b_{u} + b_{g} + \epsilon_{g,u,i}$$

Where $\hat{b_{g}}$ could be estimated by taking the average of: 
$$\hat{b_{g}} = \hat{y_{g,u,i}} - \hat{\mu} - \hat{b_{i}} - \hat{b_{u}}$$
However to ensure that the **RMSE** is not negatively affected by movies rated by very few users, regularization^[**_Chapter 33.9 - Regularization_** - https://rafalab.github.io/dsbook/large-datasets.html#regularization] is required.

\newpage

## Regularization
Regularization of each of the effects $\hat{b_{i}}$, $\hat{b_{u}}$ and $\hat{b_{g}}$ was required, to ensure the **RMSE** is not negatively affected by movies rated by very few users, and is covered below. It is worth highlighting the the equations for $\hat{b_{i}(\lambda)}$ and $\hat{b_{u}(\lambda)}$ is shown in **_Chapter 33.9 - Regularization_**^[https://rafalab.github.io/dsbook/large-datasets.html#regularization], so therefore only the equation form is shown in the interests of leaning out this report.

The equation for movie effect estimate $\hat{b_{i}(\lambda)}$ is as below:
$$\hat{b_{i}(\lambda)} = \frac{1}{\lambda + n_{i}} \sum_{n=1}^{n_{i}}{(Y_{g,u,i} - \hat{\mu})}$$

The equation for user effect estimate $\hat{b_{u}(\lambda)}$ is as below:
$$\hat{b_{u}(\lambda)} = \frac{1}{\lambda + n_{i}} \sum_{n=1}^{n_{i}}{(Y_{g,u,i} - \hat{\mu} - \hat{b_{i}})}$$


The equation for genre effect estimate $\hat{b_{g}(\lambda)}$ is as below:
$$\hat{b_{g}(\lambda)} = \frac{1}{\lambda + n_{i}} \sum_{n=1}^{n_{i}}{(Y_{g,u,i} - \hat{\mu} - \hat{b_{i}} - \hat{b_{u}})}$$
And when coded estimate $\hat{b_{g}(\lambda)}$ is as below:

```{r regularized b hat code, echo=TRUE, eval=FALSE}
  b_g <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    left_join(b_u, by="userId") %>%
    group_by(genres, userId) %>%
    summarize(b_g = sum(rating - mu - b_i - b_u)/(n()+l))
```

## Loss function
Before moving forward we will briefly go over the the **RMSE** function detailed in **_Chapter 33.7.3 - Loss function_**^[https://rafalab.github.io/dsbook/large-datasets.html#netflix-loss-function] as it was re-used to measure the accuracy of the ML model, refer to the equation and code used below:

$$RMSE = \sqrt {\frac{1}{N} \sum_{u,i} (\hat{y_{u,i}} - y_{u,i})^2}$$

```{r RMSE function, echo=TRUE, eval=FALSE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

\newpage

## Choosing the penalty term
Cross validation is used select the best $\lambda$^[https://rafalab.github.io/dsbook/large-datasets.html#choosing-the-penalty-terms], the following code was used achieve this:

```{r Choosing the penalty term, echo=TRUE, eval=FALSE}
lambdas <- seq(0, 10, 0.5)

rmses <- sapply(lambdas, function(l){
  
  mu <- mean(train_set$rating)
  
  b_i <- train_set %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - mu - b_i)/(n()+l))
  
  b_g <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    left_join(b_u, by="userId") %>%
    group_by(genres, userId) %>%
    summarize(b_g = sum(rating - mu - b_i - b_u)/(n()+l))
  
  predicted_ratings <- 
    test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_g, by= c('userId','genres'))
  predicted_ratings$b_g[is.na(predicted_ratings$b_g)] = 0
  
  predicted_ratings <- predicted_ratings %>%
    mutate(pred = mu + b_i + b_u + b_g) %>%
    .$pred
  
  return(RMSE(predicted_ratings, test_set$rating))
})
qplot(lambdas, rmses) 
```

```{r qplot, echo=FALSE, eval=TRUE ,fig.width=3, fig.height=2, fig.align='center'}
grid.arrange(p5, ncol=1, nrow=1)
```

\newpage

# Results
## Optimal lambda
For the full **_Regularized Movie + User + Genre Effect Model_**, the optimal $\lambda$ is:

```{r Optimal lambda, echo=TRUE, eval=FALSE}
lambda <- lambdas[which.min(rmses)]
```

```{r Optimal lambda2, echo=FALSE, eval=TRUE}
lambda
```

## Predicted ratings and Final RMSE
Using the optimal $\lambda$ all the effects estimates $\hat{b_{i}(\lambda)}$, $\hat{b_{u}(\lambda)}$ and $\hat{b_{g}(\lambda)}$ was re-calculated and used to create the final predicted ratings $\hat{Y_{g,u,i}}$ using the follow code:

```{r Predict ratings, echo=TRUE, eval=FALSE}
mu <- mean(train_set$rating)

b_i <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - mu - b_i)/(n()+lambda))

b_g <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by="userId") %>%
  group_by(genres, userId) %>%
  summarize(b_g = sum(rating - mu - b_i - b_u)/(n()+lambda))

predicted_ratings <- validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_g, by= c('userId','genres'))
predicted_ratings$b_g[is.na(predicted_ratings$b_g)] = 0

predicted_ratings <- predicted_ratings %>% 
  mutate(pred = mu + b_i + b_u + b_g) %>%
  .$pred
```

And the final RMSE value is:

```{r Final RMSE, echo=TRUE, eval=FALSE}
RMSE_Final <- RMSE(predicted_ratings, validation$rating)
RMSE_Final
```

```{r Final RMSE2, echo=FALSE, eval=TRUE}
RMSE_Final
```

This final residual mean squared error (**RMSE**) of **0.8575** shows that additional usage of the genre effect significantly improves the accuracy of the model.

\newpage

# Conclusion
In this **project**, we created a movie recommendation system using a large subset of the MovieLens dataset. Exploration of the _edx_ dataset showed strong evidence of a genre effect and if used to augment the **_Regularized Movie + User Effect Model_**^[https://rafalab.github.io/dsbook/large-datasets.html#recommendation-systems] could yield improvements in the accuracy of the model. This hypothesis was validated when the final model, with the addition of an regularized predicted genre effect \"*bias*\" term, yielded a residual mean squared error (**RMSE**) of **0.8575** on the _validation_ dataset.

Finally a potential limitation is the use of a common penalty $\lambda$ for each of the effects, therefore further improvement in future work to improve the prediction accuracy would be to look at incorporating individual penalty terms, $\lambda_{i}$, $\lambda_{u}$ and $\lambda_{g}$ for each of the effects.
